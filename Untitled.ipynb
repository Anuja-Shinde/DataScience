{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=2\n",
    "b=3\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS AND METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"generic-food.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv(\"IrisDataSet.csv\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "#First 5 rows of the data set\n",
    "#Shift+Tab in between the brackets of head() to know what the method does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "#no. of rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n",
    "#last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame({\"A\":[1,2,3],\"B\":[\"x\",\"y\",\"z\"],\"C\":[\"12-02-2001\",\"21-05-2016\",\"20-02-2020\"]})\n",
    "#creating our own data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([\"12-02-2001\",\"21-05-2016\",\"20-02-2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"C\"]= pd.to_datetime(temp[\"C\"])\n",
    "\n",
    "#Converting the object(String) into date format\n",
    "#temp[Col_To_Access]=pd.to_datetime(temp[On_Which_Col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"C\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime([\"2020-Sep-02\", \"abc\"], errors= \"coerce\")\n",
    "#parameter \"abc\" is not a date and to execute such data w/o error. \n",
    "#errors{‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’\n",
    "#If ‘raise’, then invalid parsing will raise an exception.\n",
    "#If ‘coerce’, then invalid parsing will be set as NaT.\n",
    "#If ‘ignore’, then invalid parsing will return the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")\n",
    "#details about the data i.e. unique values, top value, count of cols specified, mean, median, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FOOD NAME\"].value_counts()\n",
    "#count of unique FOOD NAME\n",
    "\n",
    "df[\"FOOD NAME\"].value_counts().head()\n",
    "#count of top 5 unique FOOD NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECTION OF DATA IN DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positional Indexing\n",
    "\n",
    "df.iloc[0:5,0:4]\n",
    "#iloc is accessing data frame values by rows:cols\n",
    "#first 5 rows 0:5, first 4 cols 0:4\n",
    "\n",
    "df.iloc[[0,3],0:4]\n",
    "#only row 0 and 3, first 4 cols 0:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,: -1]\n",
    "#all the rows and cols but excluding last col\n",
    "\n",
    "df.iloc[:,-1 :]\n",
    "#all the rows and only last col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anuja= df.iloc[:,-1 :]\n",
    "print(df.shape)\n",
    "anuja.shape\n",
    "#The actual dataframe 'df' doesn't get changed\n",
    "#But if stored in another variable, it's copy is made in that variable, dataframe gets changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label based indexing \n",
    "\n",
    "df.loc[:,\"FOOD NAME\"]\n",
    "#all rows and specified 'label' col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"FOOD NAME\",\"GROUP\"]]\n",
    "#all rows and only specified cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df.loc[:,\"FOOD NAME\"]\n",
    "print(type(a))\n",
    "a\n",
    "\n",
    "#when we write a single col name, it is printed in a different format w/o headings.\n",
    "#And it's data type is SERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#However if we write a single col name WITH BRACKETS () i.e. passed as a LIST \n",
    "#it is printed in a different format and WITH HEADINGS.\n",
    "#And it's data type is DATAFRAME\n",
    "\n",
    "a=df.loc[:,[\"FOOD NAME\"]]\n",
    "print(type(a))\n",
    "a\n",
    "\n",
    "\n",
    "#If passed as a TUPLE, data type remains as a SERIES\n",
    "a=df.loc[:,(\"FOOD NAME\")]\n",
    "print(type(a))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=df.iloc[0:5,[0,3]]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:4,[\"FOOD NAME\",\"GROUP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=df.iloc[[0,3],[0,2]]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[0,4],[\"FOOD NAME\",\"GROUP\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTERING OF DATA ON DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df.loc[df[\"GROUP\"]==\"Fruits\"]\n",
    "a\n",
    "#Applying a condition/filter where group==fruits\n",
    "#filter will be applied on all cols just like excel. After getting all cols as o/p in a, then we can specify any col name as shown below\n",
    "a=a.loc[:,[\"GROUP\"]]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df.loc[df[\"GROUP\"]==\"Fruits\"].head(n=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df.loc[df[\"GROUP\"].isin([\"Fruits\",\"Vegetables\"])].head()\n",
    "a\n",
    "\n",
    "#multiple conditions on a col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= df.loc[(df[\"GROUP\"]==\"Fruits\") & (df[\"SUB GROUP\"]==\"Tropical fruits\") & (df[\"FOOD NAME\"]==\"Mango\")]\n",
    "#AND condition \n",
    "\n",
    "a= df.loc[(df[\"GROUP\"]==\"Fruits\") & (df[\"SUB GROUP\"].isin([\"Tropical fruits\"]))].head()\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SORTING OF DATA ON DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= df.loc[(df[\"GROUP\"]==\"Fruits\") & (df[\"SUB GROUP\"].isin([\"Tropical fruits\"]))].head()\n",
    "a.reset_index()\n",
    "#row values of o/p is unsorted as we applied a filter. So, we can reset the index of rows.\n",
    "#'a' will have one more col 'INDEX', which is the actual row no. from original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= df.loc[(df[\"GROUP\"]==\"Fruits\") & (df[\"SUB GROUP\"].isin([\"Tropical fruits\"]))].head()\n",
    "a.reset_index(inplace=True)\n",
    "a\n",
    "\n",
    "#inplace=true means change the data frame a, i.e. rows from 0 to 10...\n",
    "#default value of inplace is false i.e. if written as 'reset_index()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= df.loc[(df[\"GROUP\"]==\"Fruits\") & (df[\"SUB GROUP\"].isin([\"Tropical fruits\"]))].head()\n",
    "a.reset_index(inplace=True, drop=True)\n",
    "a\n",
    "\n",
    "#change the dataframe a with index starting from 0 and drop the col INDEX which had old index values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"FOOD NAME\"],ascending=True).head()\n",
    "\n",
    "#sorting data where col= FOOD NAME and order of letters is ascending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"FOOD NAME\",\"GROUP\"],ascending=[True,False]).head(n=20)\n",
    "\n",
    "#Will sort FOOD NAME in ascending and then sort GROUP in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMPY AND METHODS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"Cost\"] = np.where(df[\"FOOD NAME\"]==\"Kiwi\", \"High\", \"Low\")\n",
    "df.head(n=20)\n",
    "\n",
    "#will add the col which we create= 'df[\"Cost\"]', where FOOD NAME= Kiwi by values which we provide=high/low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cost\"] = np.where(df[\"FOOD NAME\"]==\"Kiwi\", \"High\", \"Low\")\n",
    "df.loc[df[\"Cost\"]==\"High\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"]=np.array(2021)\n",
    "df\n",
    "#will add col Year with values 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cost\"] = np.where(df[\"FOOD NAME\"]==\"Kiwi\", \"High\", np.where(df[\"FOOD NAME\"]==\"Angelica\", \"Medium\", \"Low\"))\n",
    "df\n",
    "\n",
    "#nested where conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv(\"IrisDataSet.csv\")\n",
    "iris.groupby(\"Length\").agg(\"max\").head()\n",
    "\n",
    "#grouping-SAC Split, Apply, Combine\n",
    "#Split by a particular col i.e. groupby, apply  condition on same(Length)/diff col(Code) \n",
    "#i.e. agg()-aggregate and mention mean/min/max, combine data using the condition applied\n",
    "\n",
    "#Split and apply by Length, combine by max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"Length\")[\"Code\"].agg(\"max\").head()\n",
    "#Split by Length, Apply on Code, Combine by max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"Code\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby([\"Length\",\"Width\"]).agg([\"max\",\"sum\"]).head()\n",
    "#For length: calculate max\n",
    "#For Width: calculate sum\n",
    "###################################################################\n",
    "#1 col -> 1 condtion Use LIST datatype to pass parameters\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"Length\").agg([\"max\",\"sum\"]).head()\n",
    "#groupby Length and max, sum of all the remaining cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=pd.read_csv(\"atlcrime.csv\", dtype= object)\n",
    "cr\n",
    "\n",
    "#dtype=object, converted all cols to object type\n",
    "#The reason you get this low_memory warning is because guessing dtypes for each column is very memory demanding. \n",
    "#Pandas tries to determine what dtype to set by analyzing the data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr[\"date\"]=pd.to_datetime(cr[\"date\"])\n",
    "cr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr[\"beat\"]=pd.to_numeric(cr[\"beat\"], errors=\"coerce\")\n",
    "cr.dtypes\n",
    "#As all cols where of type objcets, hence converted the required cols to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= cr.groupby(\"location\").agg({\"beat\": [\"mean\"], \"date\": [\"min\", \"max\"]})\n",
    "test\n",
    "#groupby 'location' with mean of 'beat' and first and last 'date'\n",
    "#As there are multiple cols and on each col we have a condition to apply. Hence, passing it as a dictionary in agg()\n",
    "#For beat -> calculate mean\n",
    "#For date -> calculate min and max\n",
    "###################################################################\n",
    "#1 col -> multiple conditions Use DICTIONARY\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= cr.groupby(\"location\").agg({\"beat\": [\"mean\"], \"date\": [\"min\", \"max\"]})\n",
    "print(test.columns)  #3 cols\n",
    "test.reset_index(inplace= True) #index from 0,1,...\n",
    "print(test.columns)  #4 cols\n",
    "test.columns= [\"Location\", \"Average Beat\", \"Start date\", \"End date\"]\n",
    "test\n",
    "\n",
    "#After applying condition no. of cols-3, so we need to reset index to match the no. of cols (after applying condition) and (when we give custom col names)\n",
    "#We changed the name of all the cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= cr.groupby(\"location\").agg({\"beat\": [\"mean\"], \"date\": [\"min\", \"max\"]})\n",
    "test.reset_index(inplace= True)\n",
    "test.columns= [\"Location\", \"Average Beat\", \"Start date\", \"End date\"]\n",
    "test.to_csv(\"Output File.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOPS AND FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[1,2,3]\n",
    "res=[]\n",
    "for i in temp:\n",
    "    res.append(i*i)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIST COMPREHENSION IN PYTHON \n",
    "[i*i for i in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"Width\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.apply(\"mean\")\n",
    "#mean of all the integer cols\n",
    "\n",
    "#apply function works on either all the cols/all the rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.apply(\"mean\", axis=1)\n",
    "#mean of each row(will include integer values and ignore string values)\n",
    "\n",
    "#axis=0, operation on cols\n",
    "#axis=1, operation on rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.select_dtypes(include=[\"int64\", \"float64\"]).apply(\"mean\")\n",
    "#if any version of panda gives an error for string values in .csv files then we can mention type of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxHeight(Height):\n",
    "    return[\"Eligible\" if x>4 else \"Not Eligible\" for x in Height]\n",
    "iris[\"Criteria\"]=maxHeight(iris[\"Height\"])\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "def codeVal(Code):\n",
    "    values=np.where(Code==0.2, \"Yes\", \"No\")\n",
    "    return values\n",
    "iris[\"Values\"]=codeVal(iris[\"Code\"])\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxHeight(Height):\n",
    "    return[\"Eligible\" if x>4 else \"Not Eligible\" for x in Height]\n",
    "iris[\"Criteria\"]=maxHeight(iris[\"Height\"])\n",
    "\n",
    "newIris= iris.select_dtypes(include=[\"int64\",\"float64\"]).apply(maxHeight)\n",
    "#newIris-> 150rows*4cols\n",
    "#iris-> 150rows*7cols\n",
    "\n",
    "\n",
    "#CONCAT 2 data frames\n",
    "x=pd.concat([iris,newIris],axis=1)\n",
    "x\n",
    "x[\"Length\"]  #Two cols(1 iris + 1 newIris)\n",
    "#x-> 300ROWS*7cols for axis=0,rows\n",
    "#x-> 150rows*11COLS for axis=1,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOOD NAME</th>\n",
       "      <th>SCIENTIFIC NAME</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>SUB GROUP</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>907</td>\n",
       "      <td>648</td>\n",
       "      <td>907</td>\n",
       "      <td>907</td>\n",
       "      <td>907</td>\n",
       "      <td>907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>907</td>\n",
       "      <td>639</td>\n",
       "      <td>24</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Nutritional drink</td>\n",
       "      <td>Capsicum annuum</td>\n",
       "      <td>Aquatic foods</td>\n",
       "      <td>Fishes</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>166</td>\n",
       "      <td>111</td>\n",
       "      <td>905</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FOOD NAME  SCIENTIFIC NAME          GROUP SUB GROUP Cost  \\\n",
       "count                 907              648            907       907  907   \n",
       "unique                907              639             24       123    3   \n",
       "top     Nutritional drink  Capsicum annuum  Aquatic foods    Fishes  Low   \n",
       "freq                    1                6            166       111  905   \n",
       "mean                  NaN              NaN            NaN       NaN  NaN   \n",
       "std                   NaN              NaN            NaN       NaN  NaN   \n",
       "min                   NaN              NaN            NaN       NaN  NaN   \n",
       "25%                   NaN              NaN            NaN       NaN  NaN   \n",
       "50%                   NaN              NaN            NaN       NaN  NaN   \n",
       "75%                   NaN              NaN            NaN       NaN  NaN   \n",
       "max                   NaN              NaN            NaN       NaN  NaN   \n",
       "\n",
       "          Year  \n",
       "count    907.0  \n",
       "unique     NaN  \n",
       "top        NaN  \n",
       "freq       NaN  \n",
       "mean    2021.0  \n",
       "std        0.0  \n",
       "min     2021.0  \n",
       "25%     2021.0  \n",
       "50%     2021.0  \n",
       "75%     2021.0  \n",
       "max     2021.0  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
